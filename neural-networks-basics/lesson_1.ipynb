{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.30233257]\n [0.14675589]\n [0.09233859]]\n\n[[-0.69766743]\n [-0.85324411]\n [-0.90766141]]\n\n[[-1.39533485]\n [-1.70648822]\n [-1.81532281]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# генерации случайных чисел для инициализации весов\n",
    "np.random.seed(1)\n",
    "synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "\n",
    "# можем дополнительно посмотреть процесс формирования весов\n",
    "step1 = np.random.random((3,1))\n",
    "print(step1, end='\\n\\n')\n",
    "step2 = step1 - 1 \n",
    "print(step2, end='\\n\\n')\n",
    "step3 = 2 * step2\n",
    "print(step3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисление сигмоид функции. Функция активации\n",
    "\n",
    "def sigmoid(x):\n",
    "     return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисление Relu функции. Функция активации\n",
    "\n",
    "def ReLU(x):\n",
    "         return x  *  (x  >  0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "минимум 2.250004766154974, количество затраченных итераций: 580\n"
     ]
    }
   ],
   "source": [
    "# первоначальное точка\n",
    "start_point = 5\n",
    "\n",
    "# функция градиента \n",
    "gr_func = lambda x: 4 * x**3 - 9 * x**2\n",
    "\n",
    "def gradient_boost(func, start_point, learn_r=0.001, precision=0.0000001, max_n=100000000, verbose=False):\n",
    "  next_point = start_point\n",
    "  for i in range(max_n):   \n",
    "    current_point = next_point\n",
    "    next_point = current_point - learn_r*func(current_point)                                    \n",
    "    if verbose:\n",
    "      print(f\"Итерация: {iter}\")\n",
    "      print(f\"Текущая точка {current_point}| След-я точка {next_point}\")\n",
    "      print(f\"Дистан-я между текущей точк. и след. {abs(current_point - next_point)}\")\n",
    "      print(\"--------------------------------------------------------\")\n",
    "    if(abs(current_point - next_point) <= precision): \n",
    "       return (next_point, i)\n",
    "  return (next_point, max_n)\n",
    "\n",
    "\n",
    "next_point, iter = gradient_boost(gr_func, start_point)       \n",
    "print(f\"минимум {next_point}, количество затраченных итераций: {iter}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Веса инициализации: [[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "веса после завершения обучения: \n",
      "[[14.72793813]\n",
      " [-0.20316987]\n",
      " [-7.16089002]]\n",
      "Проверка на новых данных: [0, 0, 0]\n",
      "Предсказание нейронной сети: \n",
      "[0.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# генерации случайных чисел для инициализации весов\n",
    "np.random.seed(1)\n",
    "synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "print(\"Веса инициализации:\", synaptic_weights)\n",
    "\n",
    "# вычисление сигмоид функции\n",
    "def sigmoid(x):\n",
    "     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# вычисление производной от сигмоид функции\n",
    "def sigm_deriv(x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "# тренировка нейронной сети\n",
    "def train_nn(training_inputs, training_outputs, training_iterations):\n",
    "    global synaptic_weights\n",
    "    for iteration in range(training_iterations):\n",
    "        # перекачивание данных через нейрон\n",
    "        output = run_nn(training_inputs)\n",
    "\n",
    "        # вычисление ошибки через обратное распространение back-propagation\n",
    "        error = training_outputs - output\n",
    "            \n",
    "        # выполнение корректировки весов\n",
    "        adjustments = np.dot(training_inputs.T, error * sigm_deriv(output))\n",
    "\n",
    "        synaptic_weights += adjustments\n",
    "\n",
    "\n",
    "# пропускание входных данных через нейрон и получение предсказания\n",
    "def run_nn(inputs):\n",
    "    global synaptic_weights\n",
    "    inputs = inputs.astype(float)\n",
    "    output = sigmoid(np.dot(inputs, synaptic_weights))\n",
    "    return output\n",
    "\n",
    "# создание данных для обучения\n",
    "training_inputs = np.array([[0,0,1], [1,1,1], [1,0,1], [0,1,1]])\n",
    "training_outputs = np.array([[0,1,1,0]]).T\n",
    "\n",
    "# запуск тренировки нейронной сети \n",
    "train_nn(training_inputs, training_outputs, 15000)\n",
    "print(\"веса после завершения обучения: \")\n",
    "print(synaptic_weights)\n",
    "\n",
    "test_data = [0, 0, 0]\n",
    "\n",
    "print(f\"Проверка на новых данных: {test_data}\")\n",
    "print(\"Предсказание нейронной сети: \")\n",
    "print(run_nn(np.array(test_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример построения  двухслойной нейронной сети на numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'as_matrix'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-69e2efb270c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SepalLengthCm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SepalWidthCm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PetalLengthCm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PetalWidthCm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# формирование выходных данных(результатов)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Data-Science-Study-Progress/.venv/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# sklearn здесь только, чтобы разделить выборку на тренировочную и тестовую\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Шаг 1. Определение функций, которые понадобяться для обучения\n",
    "# преобразование массива в бинарный вид результатов\n",
    "def to_one_hot(Y):\n",
    "    n_col = np.amax(Y) + 1\n",
    "    binarized = np.zeros((len(Y), n_col))\n",
    "    for i in range(len(Y)):\n",
    "        binarized[i, Y[i]] = 1.\n",
    "    return binarized\n",
    "\n",
    "# преобразование массива в необходимый вид\n",
    "def from_one_hot(Y):\n",
    "    arr = np.zeros((len(Y), 1))\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        l = layer2[i]\n",
    "        for j in range(len(l)):\n",
    "            if(l[j] == 1):\n",
    "                arr[i] = j+1\n",
    "    return arr\n",
    "\n",
    "# сигмоида и ее производная\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "# нормализация массива\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)\n",
    "\n",
    "\n",
    "### Шаг 2. Подготовка тренировочных данных\n",
    "# получения данных из csv файла. укажите здесь путь к файлу Iris.csv\n",
    "iris_data = pd.read_csv(\"Iris.csv\")\n",
    "# print(iris_data.head()) # расскоментируйте, чтобы посмотреть структуру данных\n",
    "\n",
    "# репрезентация данных в виде графиков\n",
    "g = sns.pairplot(iris_data.drop(\"Id\", axis=1), hue=\"Species\")\n",
    "# plt.show() # расскоментируйте, чтобы посмотреть\n",
    "\n",
    "# замена текстовых значений на цифровые\n",
    "iris_data['Species'].replace(['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'], [0, 1, 2], inplace=True)\n",
    "\n",
    "# формирование входных данных\n",
    "columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "x = pd.DataFrame(iris_data, columns=columns)\n",
    "x = normalize(x.as_matrix())\n",
    "\n",
    "# формирование выходных данных(результатов)\n",
    "columns = ['Species']\n",
    "y = pd.DataFrame(iris_data, columns=columns)\n",
    "y = y.as_matrix()\n",
    "y = y.flatten()\n",
    "y = to_one_hot(y)\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n",
    "   \n",
    "### Шаг 3. Обученние нейронной сети\n",
    "# присваевание случайных весов\n",
    "w0 = 2*np.random.random((4, 5)) - 1 # для входного слоя   - 4 входа, 3 выхода\n",
    "w1 = 2*np.random.random((5, 3)) - 1 # для внутреннего слоя - 5 входов, 3 выхода\n",
    "\n",
    "# скорость обучения (learning rate)\n",
    "n = 0.1\n",
    "\n",
    "# массив для ошибок, чтобы потом построить график\n",
    "errors = []\n",
    "\n",
    "# процесс обучения\n",
    "for i in range(100000):\n",
    "\n",
    "    # прямое распространение(feed forward)\n",
    "    layer0 = X_train\n",
    "    layer1 = sigmoid(np.dot(layer0, w0))\n",
    "    layer2 = sigmoid(np.dot(layer1, w1))\n",
    "\n",
    "    # обратное распространение(back propagation) с использованием градиентного спуска\n",
    "    layer2_error = y_train - layer2\n",
    "    layer2_delta = layer2_error * sigmoid_deriv(layer2)\n",
    "    \n",
    "    layer1_error = layer2_delta.dot(w1.T)\n",
    "    layer1_delta = layer1_error * sigmoid_deriv(layer1)\n",
    "    \n",
    "    w1 += layer1.T.dot(layer2_delta) * n\n",
    "    w0 += layer0.T.dot(layer1_delta) * n\n",
    "    \n",
    "    error = np.mean(np.abs(layer2_error))\n",
    "    errors.append(error)\n",
    "    accuracy = (1 - error) * 100\n",
    "\n",
    "\n",
    "### Шаг 4. Демонстрация полученных результатов\n",
    "# черчение диаграммы точности в зависимости от обучения\n",
    "plt.plot(errors)\n",
    "plt.xlabel('Обучение')\n",
    "plt.ylabel('Ошибка')\n",
    "plt.show() # расскоментируйте, чтобы посмотреть \n",
    "        \n",
    "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы с вами рассматривали как сделать простые нейронные сети без использования специальных фреймворков и библиотек для этого. В следующих уроках мы с вами познакомимся как делать нейронные сети с помощью Keras и TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробуйте видоизменить параметры разобранной на уроке двухслойной нейронной сети таким образом, чтобы улучшить ее точность. Проведите анализ — что приводит к ухудшению точности нейронной сети? Что приводит к увеличению ее точности?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы разобрались с основами обучения нейронных сетей и получили некоторое представление об архитектурах простых нейронных сетей. Давайте попробуем закрепить эти знания на практике. Кроме того на примере который будет изложен ниже возможно проясняться какие-либо оставшиеся вопросы.\n",
    "\n",
    "В данном примере мы сделаем нейронную сеть которая будет отличать различные виды ириса между собой. Надо полагать данный датасет вам уже знаком. Логика работы этого кода будет такой же как и в первом разобранном примере, но только все компоненты этого кода будут несколько усложнены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные материалы\n",
    "\n",
    "<ol>\n",
    "    <li>https://medium.com/topic/machine-learning</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используемая литература \n",
    "\n",
    "Для подготовки данного методического пособия были использованы следующие ресурсы:\n",
    "<ol>\n",
    "    <li>Глубокое обучение — Николенко С. И., Кадурин 2018</li>\n",
    "    <li>Шакла Н. — Машинное обучение и TensorFlow 2019</li>\n",
    "    <li>Asifullah Khan, Anabia Sohail, Umme Zahoora, Aqsa Saeed Qureshi - A Survey of the Recent Architectures of Deep Convolutional Neural Networks 2019</li>\n",
    "    <li>A direct adaptive method for faster backpropagation learning: the RPROP algorithm - Neural Networks, 1993</li>\n",
    "    <li>Википедия</li>\n",
    "    \n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd0390d2298a449f5659aaa96af4fc8f12452db9c4eeccb2ab43eaa6eebf0025f1c",
   "display_name": "Python 3.9.3  ('.venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "390d2298a449f5659aaa96af4fc8f12452db9c4eeccb2ab43eaa6eebf0025f1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}