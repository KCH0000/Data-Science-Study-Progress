{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def loglos(y, y_pred):\n",
    "    loss = np.zeros(y.shape)\n",
    "    loss[y == 0] = -(1.0 - y[y == 0]) * np.log(1.0 - y_pred[y == 0] + 1e-14)\n",
    "    loss[y == 1] = -y[y == 1] * np.log(y_pred[y == 1] + 1e-14)\n",
    "    return np.sum(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, iterations=1e+4, alpha=1e-4, eps=1e-8, l1_alpha=0, l2_alpha=0, random_state=False):\n",
    "        self.iterations = iterations\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "        self.l1_alpha = l1_alpha\n",
    "        self.l2_alpha = l2_alpha\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.random_state:\n",
    "            np.random.seed(self.random_state)\n",
    "        W = np.zeros(X.shape[0])\n",
    "        n = X.shape[1]\n",
    "        loss_prev, loss_diff, i = 0, np.inf, 1\n",
    "        while loss_diff > self.eps and i < self.iterations:\n",
    "            y_pred = sigmoid(np.dot(W, X))\n",
    "            loss = loglos(y, y_pred)\n",
    "            loss_diff , loss_prev = abs(loss_prev - loss), loss\n",
    "            \n",
    "            l1_term = self.l1_alpha * np.sign(W) if self.l1_alpha else 0\n",
    "            l2_term = self.l2_alpha * W if self.l2_alpha else 0 \n",
    "            \n",
    "            W -= (self.alpha * (1/n * np.sum(X * (y_pred - y), axis=1)) + l1_term + l2_term)\n",
    "            i += 1\n",
    "            if i % (self.iterations / 10) == 0:\n",
    "                print(i, y_pred, '\\n', loss)\n",
    "        self.__W = W.copy()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) > 0.5).astype('int8')\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return (sigmoid(self.__W.T @ X)) \n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self.__W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450,\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, \n",
    "               1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "y = np.array([0, 0, 1, 0, 1,\n",
    "              0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(iterations=1e+7, alpha=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 [9.16340686e-02 3.33270565e-02 2.35811134e-01 5.56892898e-02\n",
      " 6.72832781e-04 1.77333374e-01 5.63134907e-04 2.74926994e-10\n",
      " 1.16558420e-01 7.46168271e-02] \n",
      " 21.35798832874148\n",
      "2000000 [3.36728474e-02 6.29693377e-03 3.48738184e-01 1.46422565e-02\n",
      " 1.29426886e-05 2.22828393e-01 1.03079985e-05 1.08107910e-17\n",
      " 5.06581225e-02 5.97882195e-02] \n",
      " 29.898020363256958\n",
      "3000000 [1.33356457e-02 1.04270084e-03 7.16862980e-01 3.74197204e-03\n",
      " 2.07253772e-06 4.33868444e-02 3.21507611e-05 5.70166370e-19\n",
      " 2.49981574e-02 9.34426251e-02] \n",
      " 29.886616356959834\n",
      "4000000 [8.21494686e-03 4.11709674e-04 9.55934659e-01 1.84364429e-03\n",
      " 3.68210034e-06 1.46197009e-02 1.19912358e-03 6.01831735e-18\n",
      " 1.72381170e-02 3.37485361e-01] \n",
      " 24.45535629778012\n",
      "5000000 [2.42227175e-03 6.58896829e-05 9.82246440e-01 3.99841063e-04\n",
      " 1.18771609e-06 1.66197762e-03 6.46056769e-03 9.29881315e-18\n",
      " 5.94693523e-03 3.78647700e-01] \n",
      " 24.804012190854127\n",
      "6000000 [2.38826544e-04 1.77587108e-06 9.49099789e-01 2.05963527e-05\n",
      " 1.04616665e-08 9.66724958e-06 1.73677696e-03 8.26330428e-18\n",
      " 8.12880461e-04 3.91109082e-02] \n",
      " 35.14006390411302\n",
      "7000000 [2.17647342e-01 2.38507947e-02 9.99999754e-01 7.61662464e-02\n",
      " 9.44435487e-01 2.57628639e-01 9.99999983e-01 5.32174564e-04\n",
      " 3.38197425e-01 9.99994845e-01] \n",
      " 1.7885494084152476\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.44706650e+01, -3.22061797e+00, -1.41044274e-02,  2.37322420e+01])"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26673438, 0.02120386, 0.99999988, 0.08153305, 0.94687631,\n",
       "       0.11691597, 1.        , 0.02438801, 0.42408326, 0.99999608])"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
